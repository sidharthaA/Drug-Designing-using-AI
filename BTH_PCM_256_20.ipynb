{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BTH PCM_256_20.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc0wpOn9hXc_"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.python.framework import ops\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "np.random.seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulaQBxDs9CqF"
      },
      "source": [
        "#import lasagne \n",
        "#import theano.tensor as T\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "#import _pickle "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUtWLmWr_i2d"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnIq2cSQEDCu"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials= GoogleCredentials.get_application_default()\n",
        "drive=GoogleDrive(gauth)\n",
        "#4/_QD_IUfoboV1WT_E8cG35ucGqNxRC0m0s7ZSWAW5iP6AVOWRpxwrWp0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fO1fLvZEe19"
      },
      "source": [
        "link='https://drive.google.com/open?id=18ayHUA1M7tcz-N6HZRvBnZkMCbFedWHv'\n",
        "#link2='https://drive.google.com/open?id=1Tj4fEXcoWBFr2ixSTd7cb5_2lPrm4F9a'\n",
        "poof,file_id=link.split(\"=\")\n",
        "#file_id2='1Tj4fEXcoWBFr2ixSTd7cb5_2lPrm4F9a'\n",
        "downloaded=  drive.CreateFile({'id':file_id})\n",
        "#downloaded2= drive.CreateFIled2':file_id2})\n",
        "downloaded.GetContentFile('compound_features_256.csv') #Training dataset\n",
        "#downloaded2.GetContentFile('AID373AID439red_test.csv') #Testing dataset\n",
        "data= pd.read_csv('compound_features_256.csv',sep=\"\\t\",header=0)\n",
        "#data2= pd.read.csv('AID373AID439red_test.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-hMJfxGkGRS"
      },
      "source": [
        "def GetFile(path,file_name,delim=\"\\t\",file_id=None):\n",
        "  \n",
        "  if not file_id:\n",
        "    poof,file_id=path.split(\"=\")\n",
        "  \n",
        "  downloaded=  drive.CreateFile({'id':file_id})\n",
        "  downloaded.GetContentFile(file_name) #Training dataset\n",
        "  data= pd.read_csv(file_name, sep=delim, header=0)\n",
        "  \n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSTzJ_4SzInp"
      },
      "source": [
        "file_id2='1qJC5BAbBUXv4VHI0eIg92G-n9z8XF-Fy'\n",
        "xyz=drive.CreateFile({'id':file_id2})\n",
        "xyz.GetContentFile('compound_additional_physchem_features.txt')\n",
        "data2 = pd.read_csv('compound_additional_physchem_features.txt',sep=\"\\t\",header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3ALOvtpFDte"
      },
      "source": [
        "file_id4='1R9NC1bIu7pJfrMVIfkNelGy1ijPaJKR3'\n",
        "abcd=drive.CreateFile({'id':file_id4})\n",
        "abcd.GetContentFile('Protein_Descriptors_20_sections.txt')\n",
        "prot_desc = pd.read_csv('Protein_Descriptors_20_sections.txt',sep=\"\\t\",header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCWnFQ_LKtza"
      },
      "source": [
        "file_id3='1SGX3gptAPDm_ZGo0_fQHdDV8ymUMwSvR'\n",
        "abc=drive.CreateFile({'id':file_id3})\n",
        "abc.GetContentFile('activity_train.txt')\n",
        "trainset = pd.read_csv('activity_train.txt',sep=\" \",header=0)\n",
        "trainset['Target_ID'] = 'CHEMBL' + trainset['Target_ID'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXFrs3LqMO8w"
      },
      "source": [
        "prot=pd.DataFrame(trainset['Target_ID'])\n",
        "prot=prot.drop_duplicates(subset=None, keep='first', inplace=False)\n",
        "prot2=prot_desc.set_index('TGT_CHEMBL_ID').join(prot.set_index('Target_ID'))\n",
        "mergedStuff = pd.merge(prot_desc,prot , left_on=['TGT_CHEMBL_ID'],right_on=['Target_ID'], how='inner')\n",
        "mergedStuff.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFaqjStCIPoq"
      },
      "source": [
        "totalcmp = data.set_index('Compound_ID').join(data2.set_index('CMP_CHEMBL_ID'))\n",
        "totalcmp.insert(0,\"Compound_ID\",list(totalcmp.index),True)\n",
        "totalcmp=totalcmp.drop_duplicates(subset=None, keep='first', inplace=False)\n",
        "train_val = pd.DataFrame(trainset[['Compound_ID','Active']])\n",
        "targetprots = trainset.set_index('Target_ID').join(prot_desc.set_index('TGT_CHEMBL_ID'))\n",
        "#targetprots = targetprots.drop(columns=['Active'])\n",
        "targetprots.insert(0,\"Target_ID\",list(targetprots.index),True)\n",
        "targetprots['Compound_ID'] = 'CHEMBL' + targetprots['Compound_ID'].astype(str)\n",
        "X_pcm = targetprots.set_index('Compound_ID').join(totalcmp.set_index(\"Compound_ID\"))\n",
        "#X_pcm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt6hEM-VhTye"
      },
      "source": [
        "y=trainset.copy()\n",
        "prot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mews2V2Gs-ot"
      },
      "source": [
        "#https://drive.google.com/open?id=1hJ28sWQ8i0oim5kCa3Fm219RvGFN2YuD\n",
        "file_id5='1hJ28sWQ8i0oim5kCa3Fm219RvGFN2YuD'\n",
        "abc=drive.CreateFile({'id':file_id5})\n",
        "abc.GetContentFile('activity_test_eval.txt')\n",
        "testset = pd.read_csv('activity_test_eval.txt',sep=\" \",header=0)\n",
        "testset['Target_ID'] = 'CHEMBL' + testset['Target_ID'].astype(str)\n",
        "testset['Compound_ID'] = 'CHEMBL' + testset['Compound_ID'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF-H1x33J92J"
      },
      "source": [
        "targetprots_test = testset.set_index('Target_ID').join(prot_desc.set_index('TGT_CHEMBL_ID'))\n",
        "targetprots_test.insert(0,\"Target_ID\",list(targetprots_test.index),True)\n",
        "#targetprots_test['Compound_ID'] = 'CHEMBL' + targetprots_test['Compound_ID'].astype(str)\n",
        "X_pcm_Test = targetprots_test.set_index('Compound_ID').join(totalcmp.set_index(\"Compound_ID\"))\n",
        "targetprots.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMfZlMAdikui"
      },
      "source": [
        "for item in prot:\n",
        "  for it in trainset:\n",
        "    if item "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ_BZGsOV1pV"
      },
      "source": [
        "def scale_data(X_train, X_test):\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    # Fit the scaler based on the training data, then apply the same scaling to both training and test sets.\n",
        "    scaler.fit(X_train)\n",
        "\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    X_train = pd.DataFrame(X_train)\n",
        "    X_test = pd.DataFrame(X_test)\n",
        "    \n",
        "\n",
        "#    if not train_fp.empty or test_fp.empty:\n",
        "#        train_fp = pd.DataFrame(train_fp)\n",
        "#        test_fp = pd.DataFrame(test_fp)\n",
        "#        X_train = pd.concat([X_train, train_fp], axis = 1)\n",
        "#        X_test = pd.concat([X_test, test_fp], axis = 1)\n",
        "\n",
        "\n",
        "    X_train = np.array(X_train, dtype=np.float32)\n",
        "    X_test = np.array(X_test, dtype=np.float32)\n",
        "\n",
        "    return X_train, X_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igrKWz2KUvzQ"
      },
      "source": [
        "#y_train=[[]]\n",
        "#y_train.shape[0] = X_pcm.shape[0]\n",
        "#y_train.shape[1] = prot_desc.shape[0]\n",
        "\n",
        "train_x, test_x = scale_data(train_x, test_x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qK8DggoFHOK"
      },
      "source": [
        "test_y = pd.get_dummies(test_y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_QlVFLir2ke"
      },
      "source": [
        "test_y.sum()\n",
        "#test_y['CHEMBL261'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgMv8ipzIIkr"
      },
      "source": [
        "#len(test_y[test_y['CHEMBL6165']==1].index.tolist())\n",
        "X_pcm_test[X_pcm_Test['Target_ID']='CHEMBL261'].tolist().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSydeILCpDkj"
      },
      "source": [
        "import io\n",
        "\n",
        "# data = pd.read_csv(io.BytesIO(uploaded['neural.csv']))\n",
        "#data = pd.read_csv(content/neural4.csv)\n",
        "data_tr = X_pcm.copy()\n",
        "data_test = X_pcm_Test.copy()\n",
        "\n",
        "\n",
        "train_x = data_tr.iloc[:,2:].values\n",
        "test_x = data_test.iloc[:,2:].values\n",
        "\n",
        "#train_x, test_x = scale_data(train_x, test_x)\n",
        "test_y = data_test.iloc[:,0]\n",
        "\n",
        "train_y = data_tr.iloc[:,0].values\n",
        "\n",
        "for idx,item in enumerate(data_test):\n",
        "  if data_test.iloc[idx,1] < 6.5:\n",
        "    test_y.iloc[idx] = None\n",
        "  \n",
        "    \n",
        "#reg_train_y=data_tr['Active']\n",
        "label=[]\n",
        "    \n",
        "#for ind,i in enumerate(data_tr['Active']):\n",
        "  \n",
        "#  if i>=6.5:\n",
        "#    x=\"Active\"\n",
        "\n",
        "#  else:\n",
        "#    x=\"Inactive\"\n",
        "    \n",
        "#  label.append(x)\n",
        "  \n",
        "''' \n",
        "for ind,trgt in enumerate(data_test['Target_ID']):\n",
        "  for idx,target in enumerate(prot_desc['TGT_CHEMBL_ID']):\n",
        "    if target==trgt:\n",
        "      y[idx].append(1)\n",
        "    else:\n",
        "      y[ind].append(0)\n",
        "      \n",
        "label2=[]\n",
        "\n",
        "for ind,i in enumerate(data_test['Active']):\n",
        "  \n",
        "  if i>=6.5:\n",
        "    x=\"Active\"\n",
        "\n",
        "  else:\n",
        "    x=\"Inactive\"\n",
        "    \n",
        "  label2.append(x)\n",
        "\n",
        "\n",
        "\n",
        "train_x = train_x.astype('float32')\n",
        "train_y = pd.get_dummies(train_y)\n",
        "\n",
        "test_x = test_x.astype('float32')\n",
        "test_y = pd.get_dummies(test_y)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x2yfWO0pE5M"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "\n",
        "rate = 0.25\n",
        "\n",
        "clf = Sequential()\n",
        "clf.add(Dense(4000, input_dim = 545, activation = 'relu'))\n",
        "#clf.add(Dropout(rate))\n",
        "clf.add(Dense(2000, input_dim = 4000, activation = 'relu'))\n",
        "#clf.add(Dropout(rate))\n",
        "clf.add(Dense(1000, input_dim = 2000, activation = 'relu'))\n",
        "#clf.add(Dropout(rate))\n",
        "clf.add(Dense(1224, input_dim = 1000, activation = 'softmax'))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.8, nesterov=True)\n",
        "adm = optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
        "clf.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'] )\n",
        " # metrics=['accuracy'], loss='mean_squared_error'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQdmgyhJpLHK"
      },
      "source": [
        "clf.fit(test_x, test_y , batch_size = 100, epochs = 50, validation_split=0.2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa7pQwgfBqID"
      },
      "source": [
        "test_x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmmIta8Oireb"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('neural.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}